{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests, json, os, time\n",
    "from requests import ConnectionError\n",
    "from dotenv import load_dotenv\n",
    "from ts_model import AutoRegressionModel, ARMA\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv('.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwelveDataApiUtils:\n",
    "    def __init__(self, symbol:str, interval:str, outputsize:int):\n",
    "        self.symbol = symbol\n",
    "        self.interval = interval\n",
    "        self.outputsize = outputsize\n",
    "        self.api_domain = 'https://twelve-data1.p.rapidapi.com/'\n",
    "\n",
    "        self.headers = {\n",
    "            \"X-RapidAPI-Key\": os.getenv('X-RapidAPI-Key'),\n",
    "            \"X-RapidAPI-Host\": os.getenv('X-RapidAPI-Host')\n",
    "        }\n",
    "\n",
    "        self.querystring = {\n",
    "            'symbol':self.symbol,\n",
    "            'interval':self.interval,\n",
    "            'outputsize':self.outputsize,\n",
    "            'format':'json',\n",
    "        }\n",
    "\n",
    "        self.dir_name_ = 'data'\n",
    "\n",
    "        self.filename = '{symbol}-{interval}.json'.format(\n",
    "            symbol=self.symbol.replace('/', '-'), interval=self.interval)\n",
    "\n",
    "\n",
    "    def writeData(self)->None:\n",
    "        if not os.path.isdir(self.dir_name_): os.mkdir(self.dir_name_)\n",
    "        \n",
    "        file = os.path.join(self.dir_name_, self.filename)\n",
    "        if os.path.isfile(file): os.remove(file)\n",
    "\n",
    "        url = f'{self.api_domain}time_series'\n",
    "        r = requests.get(url, headers=self.headers, params=self.querystring)\n",
    "        \n",
    "        with open(file, 'w') as f:\n",
    "            content = json.loads(r.text)\n",
    "            json.dump(content['values'], f)\n",
    "        f.close()\n",
    "\n",
    "\n",
    "    def appendData(self, new_content)->None:\n",
    "        file = os.path.join(self.dir_name_, self.filename)\n",
    "\n",
    "        if not os.path.isfile(file): self.writeData()\n",
    "\n",
    "        data = json.load(open(file, 'r'))\n",
    "\n",
    "        if data[0]['datetime'] != new_content['datetime']:\n",
    "            content = {\n",
    "                'datetime': new_content['datetime'],\n",
    "                'open': new_content['open'],\n",
    "                'high': new_content['high'],\n",
    "                'low': new_content['low'],\n",
    "                'close': new_content['close'],\n",
    "                'volume':new_content['volume']\n",
    "            }\n",
    "            json.dump([content] + data, open(file, 'w'))\n",
    "\n",
    "\n",
    "    def getCurrentPrice(self)->dict:\n",
    "        url = f'{self.api_domain}price'\n",
    "        r = requests.get(url, headers=self.headers, params=self.querystring)\n",
    "        return json.loads(r.text)\n",
    "\n",
    "\n",
    "    def getQuote(self)->dict:\n",
    "        url = f'{self.api_domain}quote'\n",
    "        r = requests.get(url, headers=self.headers, params=self.querystring)\n",
    "        return json.loads(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PipeLine:\n",
    "    def __init__(self, model:ARMA, td:TwelveDataApiUtils):\n",
    "        self.model = model\n",
    "        self.td = td\n",
    "\n",
    "        self.date_ = datetime.now().strftime('%Y-%m-%d')\n",
    "        self.dir_name_ = 'logs'\n",
    "        self.log_filename_ = f'log-{self.date_}.json'\n",
    "        self.closing_prices_ = None\n",
    "        self.MakeNewDataRecord()\n",
    "        self.getClosingPrices()\n",
    "        self.trainModel()\n",
    "\n",
    "        self.info_to_log_ = None\n",
    "        \n",
    "\n",
    "    def MakeNewDataRecord(self)->None:\n",
    "        return self.td.writeData()\n",
    "\n",
    "\n",
    "    def getClosingPrices(self)->None:\n",
    "        data_file = os.path.join(self.td.dir_name_, self.td.filename)\n",
    "\n",
    "        data = None\n",
    "        with open(data_file, 'r') as f:\n",
    "            data = json.loads(f.read())\n",
    "        f.close\n",
    "\n",
    "        self.closing_prices_ = pd.Series([float(i['close']) for i in reversed(data)])\n",
    "        self.closing_prices_.index = [i['datetime'] for i in reversed(data)]\n",
    "        self.closing_prices_.index = self.closing_prices_.index.astype('datetime64[ns]')\n",
    "\n",
    "\n",
    "    def trainModel(self, use_all=False)->None:\n",
    "        if not use_all:\n",
    "            return self.model.fit(self.closing_prices_.iloc[:-1])\n",
    "\n",
    "        return self.model.fit(self.closing_prices_)\n",
    "\n",
    "\n",
    "    def makePrediction(self, timestamp)->dict:\n",
    "        n = self.model.estimator_lags + self.model.q - 1\n",
    "        _input = self.closing_prices_.iloc[-n-1:-1]\n",
    "        prediction = self.model.predict(_input)\n",
    "        \n",
    "        response = {\n",
    "            'datetime':timestamp,\n",
    "            'prediction':prediction[0],\n",
    "        }\n",
    "        return response\n",
    "\n",
    "\n",
    "    def logInfo(self, record)->None:\n",
    "        if not os.path.isdir(self.dir_name_):\n",
    "            os.mkdir(self.dir_name_)\n",
    "\n",
    "        log_file = os.path.join(self.dir_name_, self.log_filename_)\n",
    "        if not os.path.isfile(log_file):\n",
    "            json.dump([record], open(log_file, 'w'))\n",
    "\n",
    "        else:\n",
    "            data = json.load(open(log_file, 'r'))\n",
    "            data = [record] + data\n",
    "            json.dump(data, open(log_file, 'w'))\n",
    "    \n",
    "\n",
    "    def getPredictionStatus(self)->dict:\n",
    "        pred_outcome = self.info_to_log_['prediction'] > self.info_to_log_['previous_price']\n",
    "        actual_outcome = self.info_to_log_['actual_price'] > self.info_to_log_['previous_price']\n",
    "\n",
    "        prediction_status = {\n",
    "            'accurate_prediction': actual_outcome == pred_outcome,\n",
    "            'predicted_to_rise': pred_outcome,\n",
    "            'rise_status': actual_outcome,\n",
    "        }\n",
    "        return prediction_status\n",
    "\n",
    "\n",
    "    def eventLoop(self)->None:        \n",
    "        cycles = 0\n",
    "        \n",
    "        while True:\n",
    "            current_quote = None\n",
    "            try:\n",
    "                current_quote = self.td.getQuote()\n",
    "            except ConnectionError:\n",
    "                print('connection error, retrying...')\n",
    "                continue\n",
    "            \n",
    "            if not current_quote['is_market_open']:\n",
    "                self.MakeNewDataRecord()\n",
    "                self.trainModel(use_all=True)\n",
    "                print('The Market is currently closed')\n",
    "                break\n",
    "            \n",
    "            last_timestamp = self.closing_prices_.index[-1]\n",
    "            quote_timestamp = pd.Timestamp(current_quote['datetime'])\n",
    "\n",
    "            if (quote_timestamp != last_timestamp) or cycles==0:\n",
    "                self.MakeNewDataRecord()\n",
    "                self.getClosingPrices()\n",
    "                \n",
    "                previous_timestamp = self.closing_prices_.index[-2].__str__()\n",
    "                previous_price = self.closing_prices_.iloc[-2]\n",
    "\n",
    "                pred_data = self.makePrediction(quote_timestamp.__str__())\n",
    "                prediction_timestamp = pred_data['datetime']\n",
    "                prediction = pred_data['prediction']\n",
    "                \n",
    "                prediction_status = None\n",
    "                if self.info_to_log_ is not None:\n",
    "                    self.info_to_log_.update(actual_price=previous_price)\n",
    "                    prediction_status = self.getPredictionStatus()\n",
    "                    self.logInfo(self.info_to_log_)\n",
    "                \n",
    "                print(\n",
    "                    f'prediction status at {previous_timestamp}: {prediction_status}\\n',\n",
    "                    f'Price at {previous_timestamp}: USD {previous_price}\\n',\n",
    "                    f'Prediction at {prediction_timestamp}: USD {prediction}\\n\\n'\n",
    "                )\n",
    "\n",
    "                self.info_to_log_ = {\n",
    "                    'previous_timestamp':previous_timestamp,\n",
    "                    'previous_price': previous_price,\n",
    "                    'prediction_timestamp':prediction_timestamp,\n",
    "                    'prediction':prediction,\n",
    "                    'actual_price':None,\n",
    "                }\n",
    "                cycles+=1\n",
    "            time.sleep(10)\n",
    "\n",
    "\n",
    "td = TwelveDataApiUtils('MSFT', '1min', 5000)\n",
    "arma_model = ARMA((2, 1), 3)\n",
    "pipeline = PipeLine(arma_model, td)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.eventLoop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.7rc1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7rc1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a926afa313b26ae1264fdcf81c726a97e69f6ba2ba780f6aa901948710f8d6e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
